{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud project: Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Data Pipeline Assignment\n",
    "\n",
    "## Objective\n",
    "\n",
    "Design and implement a data pipeline using Azure services, demonstrating skills in data production, ingestion, storage, processing, and visualization.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "### 1. Data Producer\n",
    "\n",
    "- Develop a Python script on your laptop to generate sample data in JSON format.\n",
    "- Use libraries: `json`, `random`, `datetime`\n",
    "\n",
    "### 2. Message Queue\n",
    "\n",
    "- Use Azure Storage account → queue service (or Event Hubs) for message queuing.\n",
    "    - https://portal.azure.com/?azure-portal=true#browse/Microsoft.Storage%2FStorageAccounts\n",
    "- Configure your Python producer to send data to the queue (e.g. Event Hubs).\n",
    "- Library: `azure-eventhub` (for event hubs)\n",
    "\n",
    "### 3. Serverless SQL Solution\n",
    "\n",
    "- Utilize Azure SQL Database (serverless tier) for data storage.\n",
    "- Set up auto-pause to minimize costs when not in use.\n",
    "\n",
    "### 4. Data Consumer\n",
    "\n",
    "- Create an Azure VM with Ubuntu Server 22.04 (B1s size - 1 vCPU, 1 GB RAM).\n",
    "- Develop a Python script to consume data from the queue and insert it into Azure SQL Database.\n",
    "- Libraries: `pyodbc`\n",
    "\n",
    "### 5. Grafana Dashboard (optional, see below)\n",
    "\n",
    "- Install Grafana on the Ubuntu VM.\n",
    "- Configure Grafana to connect to Azure SQL Database.\n",
    "- Create a simple dashboard to visualize the data.\n",
    "\n",
    "### 6. Power BI Dashboard (optional, see below)\n",
    "\n",
    "- Use Azure Fabric (which includes Power BI) to create a dashboard.\n",
    "- Connect the dashboard to your Azure SQL Database.\n",
    "\n",
    "### 7. Cost Analysis\n",
    "\n",
    "- Compare the costs between: a) Azure SQL Database (serverless) b) Azure VM with PostgreSQL installed\n",
    "- Assume a 10TB database for this comparison. (Do NOT create a 10TB DB!)\n",
    "- Use the Azure Pricing Calculator for estimates.\n",
    "\n",
    "## Recommended Azure Services and Tools\n",
    "\n",
    "1. Azure Queuing Service, or Event Hubs (Basic tier)\n",
    "2. Azure SQL Database (Serverless tier - select free tier and monitor costs)\n",
    "3. Azure Virtual Machines (B1s size)\n",
    "4. Data consumer, ping one or more:\n",
    "    1. Variant 1: Azure Fabric (includes Power BI)\n",
    "    2. Variant 2: Run MS PowerBI locally and connect to the cloud SQL DB\n",
    "    3. Variant 3: Run a Grafana instance and connect to the cloud SQL DB\n",
    "    4. Variant 4: Create your own web server hosting plots for the data\n",
    "\n",
    "## Cost Considerations\n",
    "\n",
    "- Utilize Azure's free tier and student offers where possible.\n",
    "- Configure auto-shutdown for the VM when not in use.\n",
    "- Use the serverless tier for Azure SQL Database to minimize costs during idle periods.\n",
    "- Monitor your Azure student account usage regularly.\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. GitHub repository (or similar) with all code (data producer, consumer, configurations, etc).\n",
    "    1. ***IMPORTANT: Never put your credentials, access tokens, keys, and other secrets in a GitHub repo! Instead, use environment variables!***\n",
    "2. Screenshots of Grafana and Power BI dashboards.\n",
    "3. A report detailing the implementation process, challenges faced, and cost analysis.\n",
    "\n",
    "## Evaluation Criteria\n",
    "\n",
    "- Functionality of the entire pipeline\n",
    "- Code quality and documentation\n",
    "- Dashboard design and usefulness\n",
    "- Accuracy and depth of cost analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Started from creating Virtual Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for data Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_sample_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            \"timestamp\": str(datetime.now()),  # Current timestamp\n",
    "            \"temperature\": round(random.uniform(20.0, 30.0), 2),  # Random temperature (between 20.0 and 30.0)\n",
    "            \"humidity\": round(random.uniform(40.0, 70.0), 2),  # Random humidity (between 40.0 and 70.0)\n",
    "        }\n",
    "        data.append(record)\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records_to_generate = 10  # You can adjust this as needed\n",
    "    sample_data = generate_sample_data(num_records_to_generate)\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    with open(\"sample_data.json\", \"w\") as json_file:\n",
    "        json.dump(sample_data, json_file, indent=2)\n",
    "\n",
    "    print(f\"{num_records_to_generate} records generated and saved to sample_data.json.\")\n",
    "\n",
    "connection_str = \"Endpoint=sb://mynewvm1.servicebus.windows.net/;SharedAccessKeyName=New_key;SharedAccessKey=rTmzn7wW3PHRmhMNeZaNDFnZh6ZtmS9v6+AEhNf0BDk=\"\n",
    "eventhub_name = \"eventhub_m\"\n",
    "producer = EventHubProducerClient.from_connection_string(connection_str, eventhub_name=eventhub_name)\n",
    "\n",
    "def send_data_to_eventhub(data):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    for record in data:\n",
    "        event_data_batch.add(EventData(json.dumps(record)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Example usage:\n",
    "sample_data = generate_sample_data(num_records_to_generate)  # Assuming you already have sample data\n",
    "send_data_to_eventhub(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubuntu login -\n",
    " ssh azureuser@20.240.202.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for sending data to Event Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "def generate_sample_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            \"timestamp\": str(datetime.now()),\n",
    "            \"temperature\": round(random.uniform(20.0, 30.0), 2),\n",
    "            \"humidity\": round(random.uniform(40.0, 70.0), 2),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records_to_generate = 10  # You can adjust this as needed\n",
    "    sample_data = generate_sample_data(num_records_to_generate)\n",
    "\n",
    "    # Replace with your actual values\n",
    "    connection_str = \"Endpoint=sb://mynewvm1.servicebus.windows.net/;SharedAccessKeyName=New_key;SharedAccessKey=rTmzn7wW3PHRmhMNeZaNDFnZh6ZtmS9v6+AEhNf0BDk=\"\n",
    "    eventhub_name = \"eventhub_m\"\n",
    "\n",
    "    producer = EventHubProducerClient.from_connection_string(connection_str, eventhub_name=eventhub_name)\n",
    "\n",
    "    try:\n",
    "        with producer:\n",
    "            event_data_batch = producer.create_batch()\n",
    "            for record in sample_data:\n",
    "                event_data_batch.add(EventData(json.dumps(record)))\n",
    "            producer.send_batch(event_data_batch)\n",
    "            print(f\"{num_records_to_generate} records sent to Event Hub.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for SQL data base to Consume the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import json\n",
    "from azure.eventhub import EventHubConsumerClient\n",
    "from datetime import datetime\n",
    "\n",
    "# SQL Server connection parameters\n",
    "sql_server = 'misbahserver.database.windows.net'\n",
    "sql_database = 'My_database'\n",
    "sql_username = 'misbahbin.hossain@yh.nackademin.se'  # Your Microsoft Entra admin email\n",
    "sql_password = 'w3dgiEf6'  # Replace with your actual password\n",
    "sql_driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Create a connection to the SQL Server using Microsoft Entra password authentication\n",
    "def create_sql_connection():\n",
    "    try:\n",
    "        # Create the connection string using Microsoft Entra Password Authentication\n",
    "        connection_string = (\n",
    "            f\"DRIVER={sql_driver};\"\n",
    "            f\"SERVER=tcp:{sql_server},1433;\"\n",
    "            f\"DATABASE={sql_database};\"\n",
    "            f\"UID={sql_username};\"\n",
    "            f\"PWD={sql_password};\"\n",
    "            f\"Encrypt=yes;\"\n",
    "            f\"TrustServerCertificate=no;\"\n",
    "            f\"Connection Timeout=30;\"\n",
    "            f\"Authentication=ActiveDirectoryPassword;\"\n",
    "        )\n",
    "        \n",
    "        print(\"Connecting to SQL Server...\")\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating SQL connection: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Function to insert data into SQL Server\n",
    "def insert_data_to_sql(timestamp, temperature, humidity):\n",
    "    try:\n",
    "        print(f\"Inserting data to SQL Server: {timestamp}, {temperature}, {humidity}\")\n",
    "        conn = create_sql_connection()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Define the insert query for your SensorData table\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO SensorData (timestamp, temperature, humidity)\n",
    "            VALUES (?, ?, ?)\n",
    "        \"\"\"\n",
    "        # Execute the query with the data\n",
    "        cursor.execute(insert_query, (timestamp, temperature, humidity))\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(f\"Successfully inserted data: {timestamp}, {temperature}, {humidity}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into SQL: {str(e)}\")\n",
    "\n",
    "# Process the received event from Event Hub\n",
    "def process_event(partition_context, event):\n",
    "    try:\n",
    "        print(\"Processing event...\")\n",
    "        event_data = event.body_as_str()\n",
    "        json_data = json.loads(event_data)\n",
    "        \n",
    "        timestamp = datetime.strptime(json_data['timestamp'], '%Y-%m-%d %H:%M:%S.%f')\n",
    "        temperature = json_data['temperature']\n",
    "        humidity = json_data['humidity']\n",
    "\n",
    "        insert_data_to_sql(timestamp, temperature, humidity)\n",
    "        print(f\"Processed event data: {json_data}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing event: {str(e)}\")\n",
    "\n",
    "# Event Hub connection parameters\n",
    "eventhub_connection_str = \"Endpoint=sb://mynewvm1.servicebus.windows.net/;SharedAccessKeyName=New_key;SharedAccessKey=rTmzn7wW3PHRmhMNeZaNDFnZh6ZtmS9v6+AEhNf0BDk=\"\n",
    "eventhub_name = \"eventhub_m\"\n",
    "consumer_group = \"$Default\"\n",
    "\n",
    "# Create a consumer client with the required consumer group\n",
    "consumer_client = EventHubConsumerClient.from_connection_string(\n",
    "    eventhub_connection_str,\n",
    "    eventhub_name=eventhub_name,\n",
    "    consumer_group=consumer_group\n",
    ")\n",
    "\n",
    "# Start receiving events\n",
    "try:\n",
    "    print(\"Starting Event Hub listener...\")\n",
    "    with consumer_client:\n",
    "        consumer_client.receive(process_event, starting_position=\"-1\")  # Receive from the beginning of the stream\n",
    "except Exception as e:\n",
    "    print(f\"Error receiving data: {str(e)}\")\n",
    "finally:\n",
    "    print(\"Closing Event Hub consumer...\")\n",
    "    consumer_client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query used inside Database to create S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE dbo.SensorData (\n",
    "    id INT PRIMARY KEY NOT NULL,\n",
    "    timestamp DATETIME NOT NULL,\n",
    "    temperature FLOAT NOT NULL,\n",
    "    humidity FLOAT NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    " sudo systemctl status grafana-server\n",
    " sudo systemctl enable grafana-server\n",
    " sudo systemctl start grafana-serve\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1962829240.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    CREATE USER ApplicationUser\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "    CREATE USER ApplicationUser \n",
    "\tWITH PASSWORD = 'Kabir.asma20';\n",
    "\n",
    "    ALTER ROLE db_datareader ADD MEMBER ApplicationUser;\n",
    "    ALTER ROLE db_datawriter ADD MEMBER ApplicationUser;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
